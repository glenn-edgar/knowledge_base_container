import os
import re
import json
import copy
import psycopg2
from psycopg2.extras import RealDictCursor
from typing import Dict, List, Any, Optional, Union, Set, Tuple
from contextlib import contextmanager
from dataclasses import dataclass
from datetime import datetime

#
#
#
#  Code generated by Claude 4.1 Sonnet
#
#
#
#
#
#

@dataclass



class TreeNode:
    """Represents a node in the tree with metadata."""

    def __init__(
        self,
        path: str,
        data: Any,
        created_at: Optional[str] = None,
        updated_at: Optional[str] = None
    ):
        self.path = path
        self.data = data
        current_time = datetime.now().isoformat()
        self.created_at = created_at if created_at is not None else current_time
        self.updated_at = updated_at if updated_at is not None else current_time


class BasicConstructDB:
    """
    A comprehensive system for storing and querying tree-structured data with full ltree compatibility.
    
    Supports all PostgreSQL ltree operators and provides seamless import/export with PostgreSQL.
    """
    
    def __init__(self,host,port,dbname,user,password,table_name):
        """Initialize the tree data storage system."""
        self.data: Dict[str, TreeNode] = {}
        self.kb_dict = {}
        self.host = host
        self.port = port
        self.dbname = dbname
        self.user = user
        self.password = password
        self.table_name = table_name
        self.connection_params = {
            'host': host,
            'port': port,
            'dbname': dbname,
            'user': user,
            'password': password
        }
        
    def add_kb(self,kb_name,description=""):
        if kb_name in self.kb_dict:
            raise ValueError(f"Knowledge base {kb_name} already exists")
        self.kb_dict[kb_name] = {}
        self.kb_dict[kb_name]["description"] = description
        
        
    def _validate_path(self, path: str) -> bool:
        """
        Validate that a path conforms to ltree format.
        
        Args:
            path: The path to validate
            
        Returns:
            True if valid, False otherwise
        """
        if not path:
            return False
        
        # ltree labels must start with letter or underscore, then alphanumeric and underscores
        # Each label can be 1-256 characters
        pattern = r'^[a-zA-Z_][a-zA-Z0-9_]*(\.[a-zA-Z_][a-zA-Z0-9_]*)*$'
        if not re.match(pattern, path):
            return False
        
        # Check each label length
        labels = path.split('.')
        return all(1 <= len(label) <= 256 for label in labels)
    
    def _path_depth(self, path: str) -> int:
        """Get the depth (number of levels) of a path."""
        return len(path.split('.'))
    
    def _path_labels(self, path: str) -> List[str]:
        """Get the labels of a path as a list."""
        return path.split('.')
    
    def _subpath(self, path: str, start: int, length: Optional[int] = None) -> str:
        """
        Extract a subpath from a path.
        
        Args:
            path: The source path
            start: Starting position (0-based)
            length: Number of labels to extract (None for all remaining)
        """
        labels = self._path_labels(path)
        if start < 0:
            start = len(labels) + start
        
        if length is None:
            return '.'.join(labels[start:])
        else:
            return '.'.join(labels[start:start + length])
    
    def _convert_ltree_query_to_regex(self, query: str) -> str:
        """
        Convert full ltree query syntax to regex.
        
        Supports all ltree operators:
        - @ - ltxtquery word separation  
        - @@ - ltxtquery full-text search
        - ~ - match lquery pattern
        - ? - match lquery with case-insensitive
        - @> - ancestor (handled separately)
        - <@ - descendant (handled separately)
        - && - overlap (for arrays)
        - Regular expressions with *{n}, *{n,m}, *{,m} quantifiers
        """
        # Handle ltxtquery format (word1@word2@word3)
        if '@' in query and not query.startswith('@') and not query.endswith('@'):
            # This is an ltxtquery format, convert @ to . for path matching
            return self._convert_simple_pattern(query.replace('@', '.'))
        
        # Convert lquery format
        return self._convert_lquery_pattern(query)
    
    def _convert_lquery_pattern(self, pattern: str) -> str:
        """Convert lquery pattern to regex."""
        # Escape special regex characters first
        result = re.escape(pattern)
        
        # Convert ltree-specific patterns
        # *{n,m} - between n and m levels
        result = re.sub(r'\\*\\\{(\d+),(\d+)\\\}', lambda m: f'([^.]+\\.){{{m.group(1)},{m.group(2)}}}', result)
        
        # *{n,} - n or more levels  
        result = re.sub(r'\\*\\\{(\d+),\\\}', lambda m: f'([^.]+\\.){{{m.group(1)},}}', result)
        
        # *{,m} - up to m levels
        result = re.sub(r'\\*\\\{,(\d+)\\\}', lambda m: f'([^.]+\\.){{0,{m.group(1)}}}', result)
        
        # *{n} - exactly n levels
        result = re.sub(r'\\*\\\{(\d+)\\\}', lambda m: f'([^.]+\\.){{{m.group(1)}}}', result)
        
        # ** - any number of levels (including zero)
        result = result.replace('\\*\\*', '.*')
        
        # * - exactly one level
        result = result.replace('\\*', '[^.]+')
        
        # {a,b,c} - choice between alternatives
        result = re.sub(r'\\{([^}]+)\\}', lambda m: f"({m.group(1).replace(',', '|')})", result)
        
        # Remove trailing dots from quantified patterns
        result = re.sub(r'\\\.\)\{([^}]+)\}', r'){{\1}}[^.]*', result)
        
        return f'^{result}$'
    
    def _convert_simple_pattern(self, pattern: str) -> str:
        """Convert simple wildcard pattern to regex."""
        
        # First handle special sequences before escaping
        parts = pattern.split('.*')
        escaped_parts = [re.escape(part) for part in parts]
        result = '.*'.join(escaped_parts)
        
        # Now handle other wildcards
        result = result.replace('\\*\\*', '.*')
        result = result.replace('\\*', '[^.]+')
        result = re.sub(r'\\{([^}]+)\\}', lambda m: f"({m.group(1).replace(',', '|')})", result)
        return f'^{result}$'
    # Core ltree operators implementation
    def ltree_match(self, path: str, query: str) -> bool:
        """
        Check if path matches ltree query using ~ operator.
        
        Args:
            path: The path to test
            query: The ltree query pattern
        """
        try:
            
            regex_pattern = self._convert_ltree_query_to_regex(query)
            return bool(re.match(regex_pattern, path))
        except Exception:
            return False
    
    def ltxtquery_match(self, path: str, ltxtquery: str) -> bool:
        """
        Check if path matches ltxtquery using @@ operator.
        ltxtquery supports word-based matching with boolean operators.
        
        Args:
            path: The path to test
            ltxtquery: The ltxtquery expression (e.g., "word1 & word2", "word1 | word2")
        """
        # Split path into words (labels)
        path_words = set(path.split('.'))
        
        # Simple ltxtquery parser - supports &, |, !, ()
        query = ltxtquery.strip()
        
        # Handle simple cases first
        if '&' not in query and '|' not in query and '!' not in query:
            # Single word query
            return query.strip() in path_words
        
        # Replace logical operators with Python equivalents
        # This is a simplified implementation
        query = query.replace('&', ' and ')
        query = query.replace('|', ' or ')
        query = query.replace('!', ' not ')
        
        # Replace words with boolean checks
        for word in re.findall(r'\b\w+\b', ltxtquery):
            if word not in ['and', 'or', 'not']:
                query = query.replace(word, f"'{word}' in path_words")
        
        try:
            return eval(query)
        except:
            return False
    
    def ltree_ancestor(self, ancestor: str, descendant: str) -> bool:
        """
        Check if ancestor @> descendant (ancestor-of relationship).
        
        Args:
            ancestor: The potential ancestor path
            descendant: The potential descendant path
        """
        if ancestor == descendant:
            return False
        return descendant.startswith(ancestor + '.')
    
    def ltree_descendant(self, descendant: str, ancestor: str) -> bool:
        """
        Check if descendant <@ ancestor (descendant-of relationship).
        
        Args:
            descendant: The potential descendant path
            ancestor: The potential ancestor path
        """
        return self.ltree_ancestor(ancestor, descendant)
    
    def ltree_ancestor_or_equal(self, ancestor: str, descendant: str) -> bool:
        """
        Check if ancestor @> descendant or ancestor = descendant.
        Equivalent to PostgreSQL's path1 @> path2 when including equality.
        """
        return ancestor == descendant or self.ltree_ancestor(ancestor, descendant)
    
    def ltree_descendant_or_equal(self, descendant: str, ancestor: str) -> bool:
        """
        Check if descendant <@ ancestor or descendant = ancestor.
        Equivalent to PostgreSQL's path1 <@ path2 when including equality.
        """
        return descendant == ancestor or self.ltree_descendant(descendant, ancestor)
    
    def ltree_concatenate(self, path1: str, path2: str) -> str:
        """
        Concatenate two ltree paths using || operator.
        
        Args:
            path1: First path
            path2: Second path
            
        Returns:
            Concatenated path
        """
        if not path1:
            return path2
        if not path2:
            return path1
        return f"{path1}.{path2}"
    
    def nlevel(self, path: str) -> int:
        """Return the number of labels in the path (ltree nlevel function)."""
        return len(path.split('.'))
    
    def subltree(self, path: str, start: int, end: int) -> str:
        """
        Extract a subtree from start to end position (ltree subltree function).
        
        Args:
            path: The source path
            start: Starting position (0-based)
            end: Ending position (exclusive)
        """
        labels = path.split('.')
        return '.'.join(labels[start:end])
    
    def subpath_func(self, path: str, offset: int, length: Optional[int] = None) -> str:
        """Extract subpath (ltree subpath function)."""
        return self._subpath(path, offset, length)
    
    def index_func(self, path: str, subpath: str, offset: int = 0) -> int:
        """
        Find the position of subpath in path (ltree index function).
        Returns -1 if not found.
        """
        labels = path.split('.')
        sub_labels = subpath.split('.')
        
        for i in range(offset, len(labels) - len(sub_labels) + 1):
            if labels[i:i + len(sub_labels)] == sub_labels:
                return i
        return -1
    
    def text2ltree(self, text: str) -> str:
        """Convert text to ltree format (basic validation and normalization)."""
        if self._validate_path(text):
            return text
        raise ValueError(f"Cannot convert '{text}' to valid ltree format")
    
    def ltree2text(self, ltree_path: str) -> str:
        """Convert ltree to text (identity function for valid paths)."""
        return ltree_path
    
    def lca(self, *paths: str) -> Optional[str]:
        """
        Find the longest common ancestor of multiple paths (ltree lca function).
        
        Args:
            *paths: Variable number of paths
            
        Returns:
            The longest common ancestor path, or None if no common ancestor
        """
        if not paths:
            return None
        
        if len(paths) == 1:
            return paths[0]
        
        # Split all paths into labels
        all_labels = [path.split('.') for path in paths]
        
        # Find the minimum length
        min_length = min(len(labels) for labels in all_labels)
        
        # Find common prefix
        common_labels = []
        for i in range(min_length):
            current_label = all_labels[0][i]
            if all(labels[i] == current_label for labels in all_labels):
                common_labels.append(current_label)
            else:
                break
        
        return '.'.join(common_labels) if common_labels else None
    
    # Storage operations
    def store(self, path: str, data: Any, created_at: Optional[str] = None, updated_at: Optional[str] = None) -> bool:
        """
        Store data at a specific path in the tree.
        
        Args:
            path: The ltree path
            data: The data to store
            created_at: Optional creation timestamp
            updated_at: Optional update timestamp
            
        Returns:
            True if successful
        """
        if not self._validate_path(path):
            raise ValueError(f"Invalid ltree path: {path}")
        
        self.data[path] = TreeNode(
            
            path=path,
            data=copy.deepcopy(data),
            created_at=created_at,
            updated_at=updated_at
        )
        return True
    
    def get(self, path: str) -> Optional[Any]:
        """Retrieve data from a specific path."""
        if not self._validate_path(path):
            raise ValueError(f"Invalid ltree path: {path}")
        
        node = self.data.get(path)
        return copy.deepcopy(node.data) if node else None
    
    def get_node(self, path: str) -> Optional[TreeNode]:
        """Retrieve the full node (with metadata) from a specific path."""
        if not self._validate_path(path):
            raise ValueError(f"Invalid ltree path: {path}")
        
        node = self.data.get(path)
        return copy.deepcopy(node) if node else None
    
    # Advanced querying with full ltree support
    def query(self, pattern: str) -> List[Dict[str, Any]]:
        """Query using ltree pattern matching (~)."""
        results = []
        
        for path, node in self.data.items():
            if self.ltree_match(path, pattern):
                results.append({
                    'path': path,
                    'data': copy.deepcopy(node.data),
                    'created_at': node.created_at,
                    'updated_at': node.updated_at
                })
        results.sort(key=lambda x: x['path'])
        return results
    
    def query_ltxtquery(self, ltxtquery: str) -> List[Dict[str, Any]]:
        """Query using ltxtquery pattern matching (@@)."""
        results = []
        for path, node in self.data.items():
            if self.ltxtquery_match(path, ltxtquery):
                results.append({
                    'path': path,
                    'data': copy.deepcopy(node.data),
                    'created_at': node.created_at,
                    'updated_at': node.updated_at
                })
        results.sort(key=lambda x: x['path'])
        return results
    
    def query_by_operator(self, operator: str, path1: str, path2: str = None) -> List[Dict[str, Any]]:
        """
        Query using specific ltree operators.
        
        Args:
            operator: '@>', '<@', '~', '@@', '||'
            path1: First operand (for @>, <@ this is the reference path)
            path2: Second operand (for operators that need it)
        """
        
        results = []
        
        if operator == '@>':  # ancestor-of
            for path, node in self.data.items():
                if self.ltree_ancestor(path1, path):
                    results.append({
                        'path': path,
                        'data': copy.deepcopy(node.data),
                        'created_at': node.created_at,
                        'updated_at': node.updated_at
                    })
        
        elif operator == '<@':  # descendant-of  
            for path, node in self.data.items():
                if self.ltree_descendant(path, path1):
                    results.append({
                        'path': path,
                        'data': copy.deepcopy(node.data),
                        'created_at': node.created_at,
                        'updated_at': node.updated_at
                    })
        
        elif operator == '~':  # lquery match
            
            return self.query(path1)
        
        elif operator == '@@':  # ltxtquery match
            return self.query_ltxtquery(path1)
        
        results.sort(key=lambda x: x['path'])
        return results
    
    def query_ancestors(self, path: str) -> List[Dict[str, Any]]:
        """Get all ancestors using @> operator."""
        if not self._validate_path(path):
            raise ValueError(f"Invalid ltree path: {path}")
        
        results = []
        for stored_path, node in self.data.items():
            if self.ltree_ancestor(stored_path, path):
                results.append({
                    'path': stored_path,
                    'data': copy.deepcopy(node.data),
                    'created_at': node.created_at,
                    'updated_at': node.updated_at
                })
        
        results.sort(key=lambda x: len(x['path'].split('.')))
        return results
    
    def query_descendants(self, path: str) -> List[Dict[str, Any]]:
        """Get all descendants using <@ operator."""
        if not self._validate_path(path):
            raise ValueError(f"Invalid ltree path: {path}")
        
        results = []
        for stored_path, node in self.data.items():
            if self.ltree_descendant(stored_path, path):
                results.append({
                    'path': stored_path,
                    'data': copy.deepcopy(node.data),
                    'created_at': node.created_at,
                    'updated_at': node.updated_at
                })
        
        results.sort(key=lambda x: x['path'])
        
        return results
    
    def query_subtree(self, path: str) -> List[Dict[str, Any]]:
        """Get node and all its descendants."""
        results = []
        
        # Add the node itself if it exists
        if self.exists(path):
            node = self.data[path]
            results.append({
                'path': path,
                'data': copy.deepcopy(node.data),
                'created_at': node.created_at,
                'updated_at': node.updated_at
            })
        
        # Add all descendants
        results.extend(self.query_descendants(path))
        results.sort(key=lambda x: x['path'])
        return results
    
    def exists(self, path: str) -> bool:
        """Check if a path exists."""
        return path in self.data and self._validate_path(path)
    
    def delete(self, path: str) -> bool:
        """Delete a specific node."""
        if path in self.data:
            del self.data[path]
            return True
        return False
    
    def add_subtree(self, path: str,subtree: List[Dict[str, Any]]):
        """Add a subtree to a specific path."""
        if not self._validate_path(path):
            raise ValueError(f"Invalid ltree path: {path}")
        if self.exists(path) == False:
            raise ValueError(f"Path {path} does not exist")

        for node in subtree:
            self.store(path + '.' + node['path'], node['data'])
        return  True
    
    def delete_subtree(self, path: str) -> int:
        """Delete a node and all its descendants."""
        to_delete = [path] if path in self.data else []
        
        # Find all descendants
        for stored_path in self.data.keys():
            if self.ltree_descendant(stored_path, path):
                to_delete.append(stored_path)
        
        # Delete them
        for delete_path in to_delete:
            if delete_path in self.data:
                del self.data[delete_path]
        
        return len(to_delete)
    
    # PostgreSQL integration
    @contextmanager
    def _get_pg_connection(self,connection_params: Dict[str, str]):
        """Context manager for PostgreSQL connections."""
        conn = psycopg2.connect(**connection_params)
        try:
            yield conn
        finally:
            conn.close()
    def import_from_postgres(self,
                            table_name: str = "None",
                            path_column: str = 'path',
                            data_column: str = 'data',
                            created_at_column: str | None = 'created_at',
                            updated_at_column: str | None = 'updated_at') -> int:
        """
        Import data from a PostgreSQL table with ltree column.
        
        Args:
            table_name: Name of the source table
            path_column: Name of the ltree path column
            data_column: Name of the data column (should be JSONB)
            created_at_column: Name of the created_at timestamp column (optional)
            updated_at_column: Name of the updated_at timestamp column (optional)
            
        Returns:
            Number of records imported
        """
        if table_name == "None":
            table_name = self.table_name
            
        with self._get_pg_connection(self.connection_params) as conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
            
                # Check if table exists
                cur.execute("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_name = %s
                    );
                """, (table_name,))
                
                if not cur.fetchone()['exists']:
                    raise ValueError(f"Table '{table_name}' does not exist")
                
                # Get existing columns and types
                cur.execute("""
                    SELECT column_name, data_type
                    FROM information_schema.columns 
                    WHERE table_name = %s;
                """, (table_name,))
                columns_info = {row['column_name']: row['data_type'].lower() for row in cur.fetchall()}
                
                # Validate required columns
                if path_column not in columns_info:
                    raise ValueError(f"Column '{path_column}' does not exist in table '{table_name}'")
                if data_column not in columns_info:
                    raise ValueError(f"Column '{data_column}' does not exist in table '{table_name}'")
                
                # Validate data column type
                data_type = columns_info.get(data_column)
                if data_type not in ['json', 'jsonb']:
                    raise ValueError(f"Column '{data_column}' must be of type JSON or JSONB, but is {data_type}")
                
                # Build select fields
                select_fields = [
                    f"{path_column}::text as path",
                    data_column
                ]
                
                if created_at_column and created_at_column in columns_info:
                    if columns_info[created_at_column] not in ['timestamp without time zone', 'timestamp with time zone']:
                        raise ValueError(f"Column '{created_at_column}' must be of type TIMESTAMP, but is {columns_info[created_at_column]}")
                    select_fields.append(f"{created_at_column}::text as created_at")
                
                if updated_at_column and updated_at_column in columns_info:
                    if columns_info[updated_at_column] not in ['timestamp without time zone', 'timestamp with time zone']:
                        raise ValueError(f"Column '{updated_at_column}' must be of type TIMESTAMP, but is {columns_info[updated_at_column]}")
                    select_fields.append(f"{updated_at_column}::text as updated_at")
                
                # Import data
                cur.execute(f"""
                    SELECT {', '.join(select_fields)}
                    FROM {table_name}
                    ORDER BY {path_column};
                """)
                
                imported_count = 0
                for row in cur.fetchall():
                    path = row['path']
                    data = row[data_column]
                    
                    # Handle JSON data if it's a string (for JSON type)
                    if isinstance(data, str):
                        try:
                            data = json.loads(data)
                        except json.JSONDecodeError as e:
                            raise ValueError(f"Invalid JSON in '{data_column}' for path '{path}': {e}")
                    
                    # Ensure data is valid JSON-serializable (dict, list, etc.)
                    try:
                        json.dumps(data)
                    except (TypeError, ValueError):
                        raise ValueError(f"Data in '{data_column}' for path '{path}' is not valid JSON-serializable")
                    
                    self.store(
                        path=path,
                        data=data,
                        created_at=row.get('created_at'),
                        updated_at=row.get('updated_at')
                    )
                    imported_count += 1
                
                return imported_count
                
                
    def export_to_postgres(self, 
                        table_name: str = "None",
                        create_table: bool = True,
                        clear_existing: bool = False) -> int:
        """
        Export data to a PostgreSQL table with ltree support.
        
        Args:
            table_name: Name of the target table
            create_table: Whether to create the table if it doesn't exist
            clear_existing: Whether to clear existing data in the table
            
        Returns:
            Number of records exported
        """
        if table_name == "None":
            table_name = self.table_name
            
        with self._get_pg_connection(self.connection_params) as conn:
            with conn.cursor() as cur:
                # Enable ltree extension
                cur.execute("CREATE EXTENSION IF NOT EXISTS ltree;")
                
                if create_table:
                    # Create table with ltree support
                    cur.execute(f"""
                        CREATE TABLE IF NOT EXISTS {table_name} (
                            id SERIAL PRIMARY KEY,
                            path LTREE UNIQUE NOT NULL,
                            data JSONB,
                            created_at TIMESTAMP,
                            updated_at TIMESTAMP
                        );
                    """)
                    
                    # Create indexes
                    cur.execute(f"CREATE INDEX IF NOT EXISTS {table_name}_path_idx ON {table_name} USING GIST (path);")
                    cur.execute(f"CREATE INDEX IF NOT EXISTS {table_name}_data_idx ON {table_name} USING GIN (data);")
                
                if clear_existing:
                    cur.execute(f"TRUNCATE TABLE {table_name}")
                
                # Export data
                exported_count = 0
                
                for path, node in self.data.items():
                    try:
                        
                      
                        cur.execute(f"""
                            INSERT INTO {table_name} (path, data, created_at, updated_at)
                            VALUES (%s, %s, %s, %s)
                            ON CONFLICT (path) 
                            DO UPDATE SET 
                                data = EXCLUDED.data,
                                created_at = EXCLUDED.created_at,
                                updated_at = EXCLUDED.updated_at;
                        """, (
                            path,
                            json.dumps(node.data),
                            node.created_at,
                            node.updated_at
                        ))
                        exported_count += 1
                    except Exception as e:
                        print(f"Error exporting path {path}: {e}")
                        continue
                
                conn.commit()
                return exported_count
    
    def sync_with_postgres(self,
                          
                          direction: str = 'both') -> Dict[str, int]:
        """
        Synchronize data with PostgreSQL table.
        
        Args:
            connection_params: Database connection parameters
            table_name: Name of the table
            direction: 'import', 'export', or 'both'
            
        Returns:
            Dictionary with sync statistics
        """
        stats = {'imported': 0, 'exported': 0}
        
        if direction in ['import', 'both']:
            try:
                stats['imported'] = self.import_from_postgres(self.table_name)
            except Exception as e:
                print(f"Import failed: {e}")
        
        if direction in ['export', 'both']:
            try:
                stats['exported'] = self.export_to_postgres(self.table_name)
            except Exception as e:
                print(f"Export failed: {e}")
        
        return stats
    
    # Utility methods
    def get_stats(self) -> Dict[str, Any]:
        """Get comprehensive tree statistics."""
        if not self.data:
            return {
                'total_nodes': 0,
                'max_depth': 0,
                'avg_depth': 0.0,
                'root_nodes': 0,
                'leaf_nodes': 0
            }
        
        depths = [self.nlevel(path) for path in self.data.keys()]
        root_nodes = sum(1 for path in self.data.keys() if self.nlevel(path) == 1)
        
        # Count leaf nodes (nodes with no children)
        leaf_nodes = 0
        for path in self.data.keys():
            has_children = any(self.ltree_ancestor(path, other_path) for other_path in self.data.keys())
            if not has_children:
                leaf_nodes += 1
        
        return {
            'total_nodes': len(self.data),
            'max_depth': max(depths),
            'avg_depth': sum(depths) / len(depths),
            'root_nodes': root_nodes,
            'leaf_nodes': leaf_nodes
        }
    
    def clear(self) -> None:
        """Clear all data."""
        self.data.clear()
    
    def size(self) -> int:
        """Get the number of nodes."""
        return len(self.data)
    
    def get_all_paths(self) -> List[str]:
        """Get all paths sorted."""
        return sorted(self.data.keys())


# Example usage and comprehensive testing
if __name__ == "__main__":
    password = input("Enter PostgreSQL password: ")
    # Initialize the enhanced tree storage system
    tree = BasicConstructDB(host='localhost',port=5432,dbname='knowledge_base',user='gedgar',password=password,table_name='tree_data')
    
    print("=== Full ltree-Compatible Tree Storage System ===")
    
    # Sample data setup
    sample_data = [
        ('company', {'name': 'TechCorp', 'type': 'corporation'}),
        ('company.engineering', {'name': 'Engineering', 'type': 'department'}),
        ('company.engineering.backend', {'name': 'Backend Team', 'type': 'team'}),
        ('company.engineering.backend.api', {'name': 'API Service', 'type': 'service'}),
        ('company.engineering.backend.database', {'name': 'Database Team', 'type': 'service'}),
        ('company.engineering.frontend', {'name': 'Frontend Team', 'type': 'team'}),
        ('company.engineering.frontend.web', {'name': 'Web App', 'type': 'service'}),
        ('company.engineering.frontend.mobile', {'name': 'Mobile App', 'type': 'service'}),
        ('company.marketing', {'name': 'Marketing', 'type': 'department'}),
        ('company.marketing.digital', {'name': 'Digital Marketing', 'type': 'team'}),
        ('company.marketing.content', {'name': 'Content Team', 'type': 'team'}),
        ('company.sales', {'name': 'Sales', 'type': 'department'}),
        ('company.sales.enterprise', {'name': 'Enterprise Sales', 'type': 'team'}),
        ('company.sales.smb', {'name': 'SMB Sales', 'type': 'team'}),
    ]
    
    # Store sample data
    for path, data in sample_data:
        tree.store(path, data)
    
    print(f"Stored {len(sample_data)} nodes")
    
    # Demonstrate full ltree query capabilities
    print("\n=== Full ltree Query Demonstrations ===")
    
    # 1. Basic pattern matching
    print("\n1. Basic pattern queries:")
    
    print("  a) All direct children of engineering:")
    results = tree.query('company.engineering.*')
    for r in results:
        print(f"    {r['path']}: {r['data']['name']}")
    
    print("  b) All descendants of engineering:")
    results = tree.query('company.engineering.**')
    for r in results:
        print(f"    {r['path']}: {r['data']['name']}")
    
    print("  c) All paths ending with 'team' type nodes:")
    all_results = tree.query('company.**')
    team_results = [r for r in all_results if r['data'].get('type') == 'team']
    for r in team_results:
        print(f"    {r['path']}: {r['data']['name']}")
    
    # 2. Advanced ltree quantifiers
    print("\n2. Advanced quantifier queries:")
    
    print("  a) Exactly 2 levels deep from company:")
    results = tree.query('company.*{1}')
    for r in results:
        print(f"    {r['path']}: {r['data']['name']}")
    
    print("  b) Between 2-3 levels deep from company:")
    results = tree.query('company.*{1,2}')
    for r in results:
        print(f"    {r['path']}: {r['data']['name']}")
    
    # 3. @ operator demonstrations
    print("\n3. @ Operator Tests:")
    
    # Ancestor tests (@>)
    print("  a) Ancestor relationships (@>):")
    test_pairs = [
        ('company', 'company.engineering.backend'),
        ('company.engineering', 'company.engineering.backend.api'),
        ('company.sales', 'company.engineering.backend')
    ]
    
    for ancestor, descendant in test_pairs:
        is_ancestor = tree.ltree_ancestor(ancestor, descendant)
        print(f"    '{ancestor}' @> '{descendant}': {is_ancestor}")
    
    # Query using @> operator
    print("  b) Find all descendants of 'company.engineering' using @> operator:")
    results = tree.query_by_operator('@>', 'company.engineering')
    for r in results:
        print(f"    {r['path']}: {r['data']['name']}")
    
    # Query using <@ operator  
    print("  c) Find ancestors of 'company.engineering.backend.api' using <@ operator:")
    results = tree.query_by_operator('<@', 'company.engineering.backend.api')
    for r in results:
        print(f"    {r['path']}: {r['data']['name']}")
    
    # 4. ltxtquery (@@ operator) demonstrations
    print("\n4. ltxtquery (@@ operator) Tests:")
    
    print("  a) Find paths containing 'engineering':")
    results = tree.query_ltxtquery('engineering')
    for r in results:
        print(f"    {r['path']}: {r['data']['name']}")
    
    print("  b) Find paths containing 'engineering' AND 'backend':")
    results = tree.query_ltxtquery('engineering & backend')
    for r in results:
        print(f"    {r['path']}: {r['data']['name']}")
    
    print("  c) Find paths containing 'frontend' OR 'mobile':")
    results = tree.query_ltxtquery('frontend | mobile')
    for r in results:
        print(f"    {r['path']}: {r['data']['name']}")
    
    # 5. Concatenation operator (||)
    print("\n5. Concatenation Operator (||) Tests:")
    
    base_path = 'company.engineering'
    extension = 'new.service'
    concatenated = tree.ltree_concatenate(base_path, extension)
    print(f"  '{base_path}' || '{extension}' = '{concatenated}'")
    
    # Store and test the concatenated path
    tree.store(concatenated, {'name': 'New Service', 'type': 'service'})
    print(f"  Stored data at concatenated path: {tree.get(concatenated)}")
    
    # 6. Complex operator combinations
    print("\n6. Complex Operator Combinations:")
    
    print("  a) All services under engineering (using ~ operator):")
    results = tree.query('company.engineering.**')
    service_results = [r for r in results if r['data'].get('type') == 'service']
    for r in service_results:
        print(f"    {r['path']}: {r['data']['name']}")
    
    print("  b) Choice patterns with quantifiers:")
    results = tree.query('company.{engineering,sales}.*')
    for r in results:
        print(f"    {r['path']}: {r['data']['name']}")
    
    # 7. ltree functions
    print("\n4. ltree Function Tests:")
    
    test_path = 'company.engineering.backend.api'
    print(f"  Path: {test_path}")
    print(f"  nlevel(): {tree.nlevel(test_path)}")
    print(f"  subpath(1, 2): {tree.subpath_func(test_path, 1, 2)}")
    print(f"  subltree(1, 3): {tree.subltree(test_path, 1, 3)}")
    print(f"  index('engineering'): {tree.index_func(test_path, 'engineering')}")
    
    # LCA test
    print("\n  Longest Common Ancestor (LCA):")
    test_paths = [
        'company.engineering.backend.api',
        'company.engineering.backend.database',
        'company.engineering.frontend.web'
    ]
    lca_result = tree.lca(*test_paths)
    print(f"    LCA of {test_paths}: {lca_result}")
    
    # 5. Tree statistics
    print("\n5. Tree Statistics:")
    stats = tree.get_stats()
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # 6. PostgreSQL integration example (commented out as it requires DB setup)
    
    
    print("\n6. PostgreSQL Integration Example:")
    print("  # Example connection parameters")
   
    
    # Export to PostgreSQL")
    exported = tree.export_to_postgres()
    print(f'Exported {exported} records')

    print("  # Import from PostgreSQL")
    imported = tree.import_from_postgres()
    print(f'Imported {imported} records')
    
   
    
    # Bidirectional sync"
    stats = tree.sync_with_postgres( direction='both')
    print(f'Sync stats: {stats}')
    
    print(f"\n=== System Ready - {tree.size()} nodes loaded ===")

